Scenario ID,Interview Phase,Timestamp,Scenario Summary,Scenario,Current Solution (if any),Desired Solution (if any)
P1-1,Interview 1,14:57,outdoor trail running,"P1 wanted to run down a paved trail through the forest. The trail periodically has roads that cross it, and there are barriers on the trail by each crossing so that cars don't drive into it. P1 wanted to run down the trail using the rolling ball attatchment for their white cane, but they were afraid of bumping into the barriers.","P1 used the marker feature in Soundscape. They first walked along the trail, and set a marker whenever they reached the gates. Then, P1 ran along the trail, and Soundscape could alert them when they were in a certain proximity to the gates. They could then slow down and walk to avoid bumping into gates. This gave them a peace of mind for running independently on the trail.","P1 would like to customize the alert threshold for each marker in Soundscape, for example, setting Soundscape to specifically alert them 30 feet before the marker. However, they doubt that this would work because of the GPS accuracy. P1 also would like to use a Siri command to be able to set markers, instead of having to manually set a marker from within the app."
P1-2,Interview 1,24:13:00,navigating college campus,P1 was navigating to a gym on a college campus. The gym was located near a wide open area and it was difficult to find the path to the door.,"P1 tried to use the marker feature of Soundscape to mark the entrance to the gym. However, the audio beacon did not work as expected, and they had difficulty passing the wide open area in front of the gym. P1 found that because of the GPS accuracy range (which is 30 or 50 feet), they couldn't tell exactly where to go. Additionally, P1 has had issues in the past with Soundscape's spatial audio feature mistakenly playing audio from the wrong direction, which is confusing. Given the accuracy range, P1 wouldn't use Soundscape for things that require them to identify the precise direction to travel in. Instead, they would use their own navigation skills, follow someone, or ask someone for directions.",
P1-3,Interview 1,31:03:00,reading and using a thermostat,P1 has a thermostat with a small black and white LED display. They want to read the screen of the display to know the current indoor tempurature so that they can then use the physical buttons on the thermostat to increase or decrease the tempurature.,"P1 tries to use Seeing AI to read the thermostat display, but most of the time it fails, presumably because of the blocky text and also the glare on the display. P1 tries to use Seeing AI from different angles or in different lighting conditions, which occasionally works.",
P1-4,Interview 1,33:34:00,sorting and reading mail,"P1 uses Seeing AI to sort and read mail. They want to quickly get a sense of what is on the outside of the envelope, in order to determine if they should open it or throw it away.","Initially, they used the 'short text' channel to quickly read the outside of the envelope, but they found it hard to understand the order of the text. They also are frustrated by Seeing AI repeating itself or changing the text that's read if they accidentally move their hands slightly. For this reason, they find it easier to use the 'document' channel for both the outside of envelopes and the letters inside.","P1 is frustrated that Seeing AI repeats text, jumps around, or reads different areas of text at once. They want a way to pause for a while while it reads, to allow them to focus on what they are listening to."
P1-5,Interview 1,33:34:00,reading product labels,"P1 wants to read labels on products, for example, cans or boxes.","P1 occasionally uses the Seeing AI 'document' channel to read text that is not on a paper document. Instead, they take a picture of the object that they wish to read, and ignore the warning from Seeing AI that says 'cannot find edges'. They find this yeilds better results than using the 'short text' channel.",
P1-6,Interview 1,40:45:00,detect color,,"P1 does not trust the color detection feature in Seeing AI, because it can give varying results for the same object.",
P1-7,Interview 1,44:15:00,check calendars and routines,"P1 wants to quickly access their mail, calendar, and reminders, which are on different platforms: GMail, Google Calendar, and Microsoft Reminders.","P1 is now able to set default platforms for mail, calendar, and reminder services on iOS, so they customized this. They then use Siri or other voice assistants to access the information.",
P1-8,Interview 1,47:20:00,play music from library,P1 wants to play music from an artist that they have saved to their library.,"P1 asks Siri to 'play Michael Jackson on Spotify', and it plays all Michael Jackson songs without considering which songs they have previously saved.",Play music from an artist while considering the songs that the user has already saved or liked.
P1-9,Interview 1,47:20:00,interact with voice assistants,,,P1 wants to customize the commands for their voice assistant so that they can say things in a more succinct way.
P1-10,Interview 1,51:53:00,check outfit,P1 wants to check the color of their clothes.,P1 calls AIRA to ask about their outfit.,
P1-11,Interview 1,51:53:00,search for products on Amazon,P1 wants to find a product on Amazon. The products (step stools) have different form factors and physical shapes. P1 wants to find out which one fits their needs.,"P1 calls AIRA to ask for help finding a specific product. They described what they wanted to the agent, and the agent described properties of the product back, like how tall they were, whether they were bulky or not, etc. Because of the qualitative and subjective nature of this task, it took some time and back-and-forth communication to get right. P1 ended up with 4-5 links for product options.",
P1-12,Interview 1,52:30:00,navigate a store,P1 wanted to find the pharmacy inside of a grocery store.,P1 called AIRA and they help them find the pharmacy.,
P1-13,Interview 1,53:06:00,call and locate an Uber in the rain,P1 left a doctors appointment and it was raining. They didn't know where to go for shelter from the rain. They also wanted to call an Uber and then find it safely.,"P1 called AIRA and they helped them locate a spot safe from the rain. The AIRA agent also helped them call an Uber. The AIRA agent saw when the Uber came into the parking lot, and they asked P1 to hold their phone up to view the parking lot. The agent saw the black car, and directed P1 to the sidewalk. The agent told P1 to raise their hand, and the Uber driver stopped in front of them.",
P1-14,Interview 1,58:31:00,navigate to a restaurant in a new location,P1 was in an outdoor shopping plaza filled with different stores with their wife. They wanted to navigate to a restauraunt.,"P1 tried using Google Maps to get walking directions to the restauraunt, but it failed because of the type of shopping plaza that they were in. P1 then switched to Nearby Explorer because it could locate things that were close to them.",
P1-15,Interview 1,59:50:00,use an instant pot,P1 wanted to read the display on their smart instant pot.,"P1 called AIRA to have them read the display because it is more accurate. While Seeing AI is free and they don't have to wait, it is less intelligent.","In interview 2, P1 mentions that a hand mounted camera for reading the text on the appliance could be useful. The text could be read out loud through their Google Home."
P1-16,Interview 1,1:02:31,find and scan barcodes on products,"P1 wants to scan the barcode on products like spices, that all have very similarly shaped containers.","P1 sometimes uses Seeing AI or other apps to try to scan the barcodes of product. However, they have a hard time aiming their phone at the object while also turning it around in their hand.","P1 thinks that more 'natural' hardware would be helpful in these scenarios. For example, if they could have a ring or fingertip device that reads whatever they put their finger on; or a pair of glasses that could track their gaze and read them whatever they are looking at. P1 thinks this is better and more efficient than aiming the phone's camera."
P1-17,Interview 1,1:02:31,find expiration dates on products,P1 wants to find the expiration date on a product like a coffee package.,,"P1 wants a way to only search for a specific piece of information, instead of having Seeing AI read everything aloud and then having to manually sort through it in their head. For example, P1 could verbally tell Seeing AI to find the expiration date, or find the shipping address, and ignore everything else."
P1-18,Interview 1,1:14:04,use a touchscreen center console display in a car,"P1 wants to control things in the car while their wife is driving, for example, switching the audio source from bluetooth to USB.",,"P1 wants something that can tell them where their fingertips are in relation to labels on the screen. Something would track their fingers and tell them where they are pointing, because they cannot ask their wife for help in this scenario."
P1-19,Interview 1,1:16:39,find desired items in a grocery store,"For example, P1 wants to find a shampoo with a specific scent.",,"P1 describes a wearable device that can connect to NFC tags embedded in products. When they touch a product, it could read aloud information about it through their headphones."
P1-20,Interview 2,1:50,find a model number on a vacuum cleaner,"P1 wanted to order a replacement part for a vacuum cleaner. They first needed to find the model number in order to search for the replacement part. First, they needed to figure out where the model number was (if it was on a sticker or engraved somewhere), and then they needed to figure out if there was a seperate model number for the specific part they wanted to replace.","P1 evenrually located a large label attatched to the vacuum and tried to use Seeing AI to read the text printed on it. However, this was difficult because of the round shape of the vacuum. Because the vacuum was older, the text on the label was also faded. They also found it difficult to hold the phone in their hand while also rotating the vacuum cleaner.","P1 highlighted that Seeing AI does not have the necessary affordances to handle this type of situation. They said that if they had the power, they would fight for policies for manufacturers to make QR codes standard on purchasable goods."
P1-21,Interview 2,13:50,identify charge level of an electric shaver,"P1 has an electric shaver that has a small display on it to show the charge level. When turning the shaver off, if the battery is less than 10%, the shaver will beep three or four times.",,"If P1 holds down the power button for five seconds, the device could beep to indicate the charge level, for example, it could beep three times to indicate 75% charge. P1 highlights that the hardware to accomplish this is already embedded in the device."
P1-22,Interview 2,21:24,take a quick voice memo,"P1 made an iOS shortcut to open the voice recorder app and start recording when they double tap on the back of the device. They noted that creating this shortcut, even as a tech-savvy person, was difficult and hard to understand.",,
P1-23,Interview 2,25:19:00,create routines on a voice assistant,P1 wants to use a voice assistant like Google Home to take notes and save them to a specific folder.,"P1 can use Google Home to take voice memos, they are saved by default to the notes section of the Google account",P1 wants to create different routines that change how notes are saved and transcribed.
P1-24,Interview 2,27:09:00,"control center console in a car (air conditioning, music)","P1 wants to control things in a car while their wife is driving. For example, control the air conditioning or music.",,P1 imagines being able to control things in the car directly from a companion app on their smartphone. This would be similar to smart appliances in the home that provide companion bluetooth applications.
P1-25,Interview 2,39:30:00,measure oil or spices while cooking,P1 wants to understand how much oil they are putting into a pot while cooking.,,"P1 imagines a device on the bottle of oil that would beep periodically for every teaspoon of oil that's poured. They note that this would be useful to other populations, not just blind people."
P1-26,Interview 2,43:00:00,use Google Maps,P1 wants to use Google Maps efficiently to navigate.,,P1 imagines customizing the homepage of the Google Maps application so that they don't see things like food options when they are trying to navigate. In this way there would be less clutter in the application.
P1-27,Interview 2,56:51:00,use/ fix a printer,"P1 has a printer that has LED lights, physical buttons, and a small screen.",,"P1 imagines an app that allows them to take a picture of the printer, send the image to a crowd source component to identify which lights are on and which icons are on the screen, and then reads the output out loud. AI could be used instead of crowd workers, depending on the capability."
P2-1,Interview 1,15:53,search for a type of business,P2 wanted to find a place for their child to take music lessons.,"P2 used Good Maps Outdoors to search for music stores. They got a list of stores, including how far they were and how to get there.",
P2-2,Interview 1,"19:03, 1:01:06",cross streets,"When navigating through an intersection where they need to cross the street twice, P2 sometimes doesn't know which way they can cross first.","P2 uses Good Maps Outdoors to find the push buttons when crossing the road. P2 would listen carefully to the traffic to tell from which direction the traffic is coming or going. However, when there are two lanes, it's hard for them to tell the traffic on the more distant lane.","The app could tell them how they can cross the crossroad safely, by pointing out which side of the road or direction they should walk. The app could use online traffic signal data to figure out when a walk sign is on. It could combine this data with information from the camera and microphone. Any additions should be directly integrated with their current mapping application."
P2-3,Interview 1,24:02,follow directions while navigating,P2 needs to know how far they should walk until they should turn.,"P2 uses Good Maps Outdoors. They tried using Google Maps, but it doesn't tell them how many more steps to take, or give them clockwise directions (i.e., turn left 9 o'clock)",
P2-4,Interview 1,"28:09, 32:00",sort meals/ products,"P2 wants to know whether meals are for themselves, their spouse, or their son.","P2 used Seeing AI to read product labels. They note that holding the phone to capture the text well is difficult (their hands move, they don't know where to point).","Seeing AI could give out instructions like ""move your camera higher/ lower/ closer"" when it detects camera is not positioned correctly. P2 notes that KNFB reader used to do something like this."
P2-5,Interview 1,"29:33, 42:28, 1:08:36",play with family members,"P2 wants to play games with their kids, like hide and seek, or guessing the mucisian of a song.","P2 used Seeing AI personal recognition channel to recognize kids and have fun when the age detection gives out incorrect ages. Their 7-year-old child was said to be 13.
P2 used Alexa to play a ""guess the musician"" game. They let Alexa play a song and guessed the musician with their kids.","P2 also wanted more ways to enrich their life, like playing with their kids outdoors or playing soccer. They used to have a ball that would make a lot of sound when being kicked. It would be good to develop some apps or games so that one could play with friends or family members. 
""It would gives you another way to integrate with other, with the society... When others are playing with your kid or whenever others are playing with each other, you are not sitting on the sidelines."""
P2-6,Interview 1,29:33,check clothes,P2 wanted to check their outfits' colors.,P2 used Seeing AI color recognition channels.,
P2-7,Interview 1,35:20,reading short text,P2 wanted to read product labels or mail address (short text).,"P2 used Seeing AI short text channel to read. P2 notes that while Seeing AI gives errors when they read long documents, it's fine for these shorter tasks.",
P2-8,Interview 1,36:44,use function keys on laptop,,P2 uses braille stickers on their function keys so that they do not have to count each one.,
P2-9,Interview 1,39:42,find information online,P2 wants to quickly search for information about specific products.,"P2 uses Alexa to search on Google. But, they worry about the privacy issues with Alexa as it is always listening. They note that when Alexa asks to associate their voice to a name, they always decline.",
P2-10,Interview 1,"45:11, 49:43",purchase an accessible TV,"P2 wanted an accessible TV that can speak when they change channels or increase volumes, so that they can watch TV independently. But they also wanted the device to work for all of their family members.",,"P2 wanted the TV to work for sighted people too. There should be an easy way to turn the accessibility features on and off, with a single button. So that when their family members use the TV they won't be bothered by the voice."
P2-11,Interview 1,57:38,cooking,P2 wants to cook a meal for themselves.,"P2 has many cans of food and they need to locate specific ingredients. They used Seeing AI to find the cans. Then, they wanted to get the recipe so they asked Alexa to get the recipe, and Alexa read out the recipe to them.",It would be great if there are smoother ways to switch between apps.
P2-12,Interview 1,1:14:28,read prescriptions,P2 wanted to read their prescriptions.,"CVS has an app, Spoken RX, that tags in their prescriptions. P2 use the app to read out the prescriptions.",
P2-13,Interview 2,2:11,read charts and graphs,P2 wants to read charts but they are often not accessible. This has affected adversely their own education and the qualifications that they could obtain.,,"Sonification could be used. For example if there is a line that goes higher up in the graph, there will be an increased pitch. If a cursor is touching that line, it could also read out the underlying data. The system could also read out color information or use sound to show that. "
P2-14,Interview 2,10:04,represent self on social media with an avatar,"P2 want to create and customize avatars and profile photos, and upload them to social media websites.",,Accessible image editing software and better AI-generated image descriptions could help.
P2-15,Interview 2,19:05,use VR/AR,,,"P2 thinks VR could be involved more in higher education.  For example, if someone in a wheelchair wants to attend a meeting or workshop, it's inconvenient for them to physically move around. If VR based remote working environment is possible, people with disabilities would benefit and can get more training."
P2-16,Interview 2,25:47,use team collaboration tools,"When P2 is working they need to use Asana. It's a visual tool, has no keyboard navigation, and doesn't work with screen readers. What they can do at best is to read only the data that has been entered, but they have no way to do any kind of data entry. Disabling keyboard navigation also prevents people with motor disability from using the software. Similar things happened to WebEx. In contrast, Zoom is very accessible.",,
P3-1,Interview 1,4:05,skim printed text,P3 wants to skim printed text to determine if it is important and if they should read it further.,"P3 uses Seeing AI, and similar mobile OCR apps on Android. P3 tends to not rely on these apps though for excessively important tasks. If they wanted to read it further, they might switch over to Be My Eyes or Aira.",
P3-2,Interview 1,4:05,identify currency,,"P3 uses Seeing AI, and similar mobile OCR apps on Android.",
P3-3,Interview 1,4:05,read text in a mobile screenshot,,"P3 uses Seeing AI, and similar mobile OCR apps on Android.",
P3-4,Interview 1,11:16,operate a microwave,P3 wanted to read the timer or button text on a microwave.,"P3 tried using Seeing AI, but it did not work (it was not recognizing the text), so they resorted to using Aira.",
P3-5,Interview 1,17:17,navigate college campus with winding paths,,"P3 is still working on forming a workflow. They have tried Soundscape and Blind Square, but both of these rely on Open Street Maps data which is not complete on their campus. Google Maps doesn't have the same accessibility features, for example, reading out different points of interest. P3 tried to use the marker feature in Soundscape to mark the location of their dorm, but found that it did not do a good job directing them back to that point.",It's easy to lose directions on winding paths. So a tactile compass plus cardinal directions are useful.
P3-6,Interview 1,23:08,get food from the dining hall,"P3's dining hall had 24/7 service. Once in the middle of the night, P3 decided to get some snacks. Instead of looking for a specific item they were just looking around. There were no humans around to assist.","P3 used AIRA instead of Be My Eyes. BME might be a bit tricky in terms of trying to scan the entirety of that semi-large space, which is not very efficient. AIRA's agents are trained so they are more reliable.",
P3-7,Interview 1,27:07,use Microsoft Word,"P3 uses Microsoft Office, like Word with an accessible document, or browsing web page on Microsoft Edge.",P3 uses Be My Eyes' Microsoft specialists to ask for help,
P3-8,Interview 1,"28:16, 30:33",navigate an inaccessible website,P3 was attending a virtual career fair. And the platform was inaccessible. P3 didn't have too much time to troubleshoot accessibility issues.,P3 called Be My Eyes,
P3-9,Interview 1,30:33,navigate around campus,,"P3 tried to label a few points of interests. P3 might use Be My Eyes to plan out a route to get from one place to the other on campus, just just like describing map data from Google Maps.",
P3-10,Interview 1,30:33,use dorm laundry machines,,P3 tried to label a few machines with tactile stickers. OCR apps would read out all buttons on machines at once and P3 can't seperate them.,
P3-10,Interview 1,31:26,read mail,,P3 used Be My Eyes.,
P3-11,Interview 1,31:26,read numbers on covid test kit,,P3 used Be My Eyes. P3 didn't use OCR because inaccurate numbers would prevent them from activating the kit.,Human assistance is not ideal for privacy reasons.
P3-12,Interview 1,39:43,sort clothes,P3 wanted to sort their clothes.,P3 video called their family members,"An AI system could differentiate between a bunch of different clothes (e.g. sort based on color, or type outdoor/ indoor/ formal/ leisure). First, they could display the clothes to the system, then add their own label to the clothing. Later you could display an item to the system, and the system could tell which type of clothing you're holding."
P3-13,Interview 1,44:40,prepare resume,,"The process requires formatting a lot so P3 asked help from other people (friends, family)","It's hard to make this accessible. Even though they can get a sense of the styling applied to different parts of the text, they can't get a sense of the overall layout."
P3-14,Interview 2,00:53,have Zoom meetings,"P3 wants to ensure other people can properly see them in conferences, meetings, family calls, and work interviews. They want to center themselves and ensure their head is not too small or leaving the frame.",P3 asks someone for help before the call,An extension to Zoom or other video conferencing applications with a camera that can detect the face of users and instruct users to move their position to the center.
P3-15,Interview 2,05:23,use function keys on keyboard,"When a screen reader user is exploring a new keyboard, the ideal way is to enter ""input help mode"" for your screen reader, and press around and your screen reader will simply announced the request without performing any action. However, this mode tends to not support secondary actions on function keys. So f1 might lower
volume, increase brightness, or mute something. It is helpful to be able to know what the function of that is.","P3 used AIRA. P3 using phone's camera to show the top row
of their new Bluetooth keyboards. And AIRA were able to describe the icons on them, based on which P3 guessed what visual icon might suggest.",Seeing AI should be able to read out keys or other buttons logically.
P3-16,Interview 2,10:54,outdoor navigation,,,"Have a camera on smart glasses, or a camera on another wearable device. Use AI to simulate how a guide dog would work. For example, P3 enter a new space, and they want to find the nearest stairs. Camera then scans, detect the stairs, and give out instructions on how to approach that stairs."
P3-17,Interview 2,35:38,multi-task with white cane,"P3 has to sometimes navigate with their cane, hold something in their hand, and get their key to unlock their door.",,"If a cane could have a temporary state where it could somehow be used hands-free, that would be helpful. For example, the cane could be able to be propped up on its own temporarily with some hardware on the bottom."
P4-1,Interview 1,6:02,understand surroundings,"P4 wants to have a mental image of the things that are around them. For example, there is a closet to the right side and there's a table on the left.",P4 used Seeing AI.,
P4-2,Interview 1,16:55,organize bookshelf,"P4 wanted to organize their bookshelf and find sections for fiction, sci-fi, nonfiction, etc.","P4 drew simple shapes and colored them. P4 created stickers and used them as labels, putting them on different sections. P4 used Seeing AI to scan their surroundings and find shapes (e.g., label a circle for non-fiction section of bookshelf. If Seeing AI finds a ""circle"", they know it's the non-fiction section).",Use a 3d printer to print out shapes so that P4 can touch and feel the labels.
P4-3,Interview 1,21:19,navigate outdoors,"P4 wanted to walk around the backyard in the vicinity of their house, which didn't have a main road. P4 was trying to navigate through the footpath which did not have a lot of obstacles, but then they were unaware of any new lampposts or perhaps any new obstacle in the middle. 
P4 found that was a bit of a struggle, because they always move the phone around in a way where it felt like they were capturing someone's picture. People passing by got a little conscious.","Currently Seeing AI can’t tell proximity information. 
When aiming camera straight, Seeing AI can’t tell what’s on the ground (e.g. object on the floor), but can only tell what’s in front of the user.",
P4-4,Interview 1,03:52,assemble Ikea furniture,"P4 needs to fix an IKEA table. P4 needed to find tools. They only remembered it's on a surface, but can't remember the exact location.","P4 used Be My Eyes. Volunteers can give a lot of recommendation in terms of how to fix a problem. For example, they weren't sure how to screw the bolt. Volunteers gave very handy tips on like to safely finish the task. Volunteers also notified them of sharp items at the edge of the bed.",
P4-5,Interview 1,04:37,find/ organize food,P4 wanted to know what in their fridge is close to expire or perish.,P4 used Be My Eyes.,
P4-6,Interview 1,8:00,find outfits,P4 wants to get recommendations for their outfits.,P4 used Be My Eyes to get a human opinion.,
P4-7,Interview 1,10:52,solve a Rubik's Cube,P4 was trying to solve a Rubik's Cube,"P4 tried Seeing AI, but it wasn't very helpful to really understand what tiles they were touching. It gave color information without context. P4 used Be My Eyes instead.",
P4-8,Interview 1,10:52,Read text,P4 wants to only read out headings / bold / highlighted text inside a paragraph.,P4 used BME.,
P4-9,Interview 1,14:03,Identify money,,P4 used Tap Tap See.,
P4-10,Interview 1,00:23,cleaning and locating items,"P4 dropped some milk on the table/ floor without noticing it. Meanwhile, P4 is trying to find clothes.",P4 used Be My Eyes and unexpectedly the volunteer notified P4 of the spilled milk.,
P4-11,Interview 1,16:57,emergency situations,P4 heard odd noises.,"Be My Eyes volunteers told them there was some broken glass so they knew what happened, and helped them navigate in the room.",
P4-12,Interview 1,25:57,find expiration dates,,,Human help is preferred
P4-13,Interview 1,25:57,know color of clothes,,"Sometimes uses Seeing AI, but they always check the item under different lighting conditions to make sure.
",Human help is preferred because lighting and materials would influence AI's capabilities.
P4-14,Interview 1,30:28,browse online,"P4 sometimes shops online, but describes Amazon as confusing as there is a lot of buttons and they often end up on the wrong page.",,P4 can use voice command or finger gestures to open Amazon and browse products.
P4-15,Interview 1,36:29,understand space,"P4 wants to understand how their house looks every day. They want to know whether any layout or major things have changed, like if they put their laptop on the bed instead of the desk yesterday).",,Have one 360 degree camera that can map things around them. P4 can also know how far are things from where the camera was positioned. The map can also provide guidance on how they can walk through the house.
P4-16,Interview 2,09:47,synchronization between different devices,"P4 wants to use Google Home (which can be voice controlled) to connect with phones and send emails, messages, etc.",,
P4-17,Interview 2,13:58,outdoor navigation,P4 wants to avoid obstacles when walking outside.,P4 tried a service dog and found it very efficient. P4 can walk confidently and indepently. Dogs are also good buddy and companion.,
P4-18,Interview 2,22:10,understand space,,P4 used Seeing AI object recognition for the first time to get an idea of how their home looks like and find out misaligned objects.,
P4-19,Interview 2,26:12,understand space,,,P4 hoped wearable device can combine with Seeing AI to improve efficiency (e.g. glasses can replace phone camera)
P4-20,Interview 2,32:32,navigate stairs,"P4 would encounter slopes or staircases, which is dangerous and they might fall from the stairs.",,"Near the stairs, the ground could have different or irregular surface. This can warn blind people of incoming stairs."
P5-1,Interview 1,06:56,Read meme,,P5 put them into KNFB Reader to know the words in memes. Then they ask their friends to describe the pictures.,Some technologies can have auto generated image description.
P5-2,Interview 1,06:56,Read documents,,P5 use KNFB Reader,
P5-3,Interview 1,10:27,Read kiosk,"P5 wanted to use an ATM at a train station. Normally the ATM itself can speak, but on that day it was broken.","P5 knew the screen they needed, so they used KNFB Reader to describe the screens to find the one they were looking for.",
P5-4,Interview 1,09:12,Read pop-ups,P5 wants to read the pop-ups on their computer.,P5 uses KNFB Reader,
P5-5,Interview 1,11:21,Read a piece of text,P5 wants to know / keep a piece of text.,"When P5 was in class, they used KNFB Reader to take pictures of their friend's book. It's very convinent and easy for on-the-go text scan. They also used KNFB Reader in library that they take a picture of a journal.",
P5-6,Interview 1,14:42,Read hand-writing notes,P5 wants to read hand-writing notes.,,Let SA or KNFB Reader to have more accurate hand-writing detection.
P5-7,Interview 1,16:04,Read food label,P5 is vegan and they wants to know the text on a food can. Seeing AI can't read all text accurately. It can't differentiate commas or parentheses. All text would be squeezed together. KNFB also can't do this well.,Seeing AI can't read all text accurately. It can't differentiate commas or parentheses. All text would be squeezed together. KNFB also can't do well. P5 went to Instacart to read the ingredients there.,
P5-8,Interview 1,20:37,Shopping,P5 went to a store and wanted to find a worker to help them.,P5 used AIRA.,
P5-9,Interview 1,20:37,Set up car seat,P5 wanted to set up a car seat.,P5 used AIRA.,"The activity of following instructions (e.g. set up car seat, cooking,) we could have a system to find instructions for us. Users can directly search for instructions and be instructed step by step. There could also be a ""scan"" option that you can switch over to camera view to find the item you need. "
P5-10,Interview 1,20:37,Cross the street,P5 wanted to cross the street when it was very windy and they couldn't hear the incoming cars.,P5 used AIRA.,
P5-11,Interview 1,25:53,Indoor navigation,P5 was at a mall and there was a time crunch they didn't have the ability to explore the mall.,P5 called AIRA. The agets took them to a mall map and found where they was. They quickly found the way P5 needed.,"Some automated, integrated system is possible, combined with the mall map.

If P5 wants to find a garbage can, they could be given solid directions with speech or vibration like those in Google Maps or Apple Maps. The system also have scanned along features, so that P5 could see what they were passing as they go. It would also have some options to detect “where I'm standing and what angle”"
P5-12,Interview 1,27:59,Navigating outdoors at night,"Sometimes the environment is dark, or P5 needs to hold the hand of their child / cane.",,Sometimes P5 don't want to have their phone out and it would be great to have glasses.
P5-13,Interview 1,30:42,Take public transportation,"P5 went to Virginia, where the buses didn't speak.","P5 used Move It (app) which notified them of every stop. 
To avoid connection route planning issue, they first use google maps to get the routes, and then use Move It to take the transportation.",Move It could have better route planning and better intermediate notification.
P5-14,Interview 1,35:12,Navigate to places nearby,P5 went to a guitar store and wanted to find food places nearby.,P5 used Blind Square that can give clockwise direction.,
P5-15,Interview 1,35:12,In a vehicle,,"When P5  was getting close to destination, BS told them what they were passing, which can help them get their bearings on where they were.",BS's own voiceover often crashed with iphone's voiceover.
P5-16,Interview 1,43:10,Indoor navigation,"Before riding a uber, P5 wanted to know the incoming car's license plate.",,
P5-17,Interview 1,48:19,Make cookie,,,"P5 don't want to read the back of the container. They could directly search the name, have the list of instructions come up step by step. 
One steps is to crack two eggs and beat them. There could be a scan button
to say ""need help finding eggs"" and another button of ""complete. I don't need help. "" When you turn on scan, it would open up that camera to help you find what you need."
P5-18,Interview 1,49:39,Spice rack,,,"Let each product has a QR code or barcode so that scanning them would connect to a database. Searching inside the database would enable people to know the information they need.
P5 could create a tag of ""turkey seasoning"" and put 10 seasoning into the tag group. They can then scan their shelf, and it the camera find one of the seasoning, the phone beep to notify P5 to get the seasoning.
In stores, scanning items to help users to find things on their shopping list."
P5-19,Interview 1,58:08,Shopping,P5 went shopping in a store and wanted to know the price and size of clothes.,,"Let SA have a new ""tag reader"" channel."
P5-20,Interview 2,03:44,Set up FireStick,"P5 set up an iPad the other day, and love that they're able to use the same shortcut that they're accustomed to for voice over. P5 wish there were something like that for other electronics that they need to set up, like the Amazon fire stick.",,"When p5 were setting the iPad up, they just press the home button three times, then voiceover came on. When they're setting up the fire stick, it would be preferable if there was some sort of description earlier on of how they could turn on voiceover on fire stick."
P5-21,Interview 2,06:24,Use toaster,"P5 tried to use camera to zoom in on the toaster to read the settings, but since it’s much older, they couldn’t do that because it was so small and was in an awkward places. P5 wish there was more available AT that could help with the use of in-home appliances for blind individuals.",,"P5 could use phone to scan the barcode and connect to the device, and then control everything on phone.

But it's also important to know the screen of those device. They wanted to know the layout of buttons. For example, they might still need to press some buttons. If there're 8 buttons in 2 row (4 in each row) and some screen readers give out 8 buttons' text all in once, they can't know how to press the button.

The system can also support explore mode. They can combine with finger detection to tell the users which button they're on."
P5-22,Interview 2,16:06,Ride uber,"Before riding a uber, it's hard to tell where's the car. P5 wish there were an option builted to the app or into another app that would notify them of where the car is and how close they're getting to it. This is helpful in public.",,Have a license plate reader.
P6-1,Interview 1,17:15,Read labels,"P6 wants to check what food/ liquid /medication they have in the refrigerator, or to differentiate shampoo and conditioner",P6 used Seeing AI,After scanning a barcode they could be directed to a website with more information
P6-2,Interview 1,17:15,Read screens,"P6 wants to read computer screen when screen reader cannot work normally, or to read what’s highlighted, to read what’s checked in a form.",P6 used Seeing AI,
P6-3,Interview 1,24:07,Read forms,"P6 scaned a document with lots of columns, but it’s hard for Seeing AI to pull out the information they specifically want.",,
P6-4,Interview 1,24:07,Multiple languages,Seeing AI document channel cant work well when a doc has multiple languages on one page.,,
P6-5,Interview 1,28:22,Fill out a form,P6 wants an app to detect checkboxes on a screen or in a form.,,
P6-6,Interview 1,34:58,Open space navigation,"On a college campus or a music festival, the space is very open. P6 want to be able to walk around. They want to mark places like bathrooms or stages in musical festivals, and they want to customizedly name them.",,
P6-7,Interview 1,48:23,Indoor navigation,P6 and their friend want to go through an airport without a sighted help.,P6 used Be My Eyes. Agents would pull up a map or have them to move the camera around to know where they were. BME can guide them to safely walk through Starbucks and let them stop by security checkpoint.,"Human service is more helpful than AI on tasks that are more complicated. But simple tasks like going through airports or buildings could be handled better with AI.
There could be a system where direction information can be shown in forms of different fluorescent lightning. Airport can cooperate with AIRA so that AIRA agents can understand the meaning of lightning and thus guide people. AIRA's agents are trained so they can do better than  BME's volunteers. "
P6-8,Interview 1,55:46,Health device,P6 wants to track their blood sugar level.,"There is a FDA approved patches for reading people's blood sugar. It's connected with their smartphones and can track blood sugar level in real time, so that users can plan their diet accordingly.",
P6-9,Interview 1,56:46,Fitness equipment,"P6 wants to use fitness equipment, but there's not many accessible fitness equipment with touch screens. There ought to be a standard interface that the equipments can talk to users, telling them information like calories burnt, miles run, etc.","P6 asked people around them for information they needed becasue they don't have time to hold the phone and scan the screen. 
There is also a company that have their rowing machine accessible by having a connected phone app to speak out information.
P6 also used an app called Interval Timer. If they're on a elliptical or whatever and wanted to know during a 30 minute workout, when to speed up or slow down, the app can speaks with VoiceOver.",P6 wants more smart device or assistive technologies related with health monitoring and fitness.
P6-10,Interview 1,59:28,Help others,P6 wants to help other BVI people by using recording or other forms of demonstration.,P6 combined Facetime and Seeing AI.,
P6-11,Interview 1,1:02:03,Track sleeping,P6 wants a device to detect whether they're asleep. If they're asleep during day time the device can wake them.,,"The watch can use sensors to detect EEG, heartrate, breathing, blood oxygen level, etc,  combining them to detect whether the user is asleep. The app is also useful for drivers. 
The app can give an electric shock or connect to some other speaking devices to wake people up."
P6-12,Interview 1,1:07:04,Use musical instrument,P6 wants accessible recording equipment or musical instrument.,There was an music production equipment in 2016 to make their keyboards accessible. But the installation process and setting for the app is inaccessible.,
P6-13,Interview 1,1:11:17,Find places,P6 want to find points of interest or obstacles.,,Users have to walk around in that room and the assistive app would be on constant video. It would prompt you if you entered the door. It would tell you to scan the room or map. The app would go through the map you know where all the objects are. You can walk around the room and tell it to find a table.
P6-14,Interview 2,01:56,Read screens,P6 wanted to upgrade their computer to Win10 and remove some spyware. There was no people around them. But because the computer is updating they can't use screenreader.,P6 used BME to troubleshoot problems during the process. Some friends of them also used AIRA throughout the upgrading process for step by step guidance.,
P6-15,Interview 2,04:46,Smart glasses,"P6 wants smart glasses and can combine them with BME, AIRA, etc. So that they don't need to cover their ears with headphones and don't need to hold their phones. Ideally there could be seamless bionic integration in the future.
However, prices of current glasses are too high. P6 also worried about privacy issue. Control needs to remain in the hands of the person and the people concerned; people should always at least get consent to know that they're being recorded.",,
P6-16,Interview 2,13:45,Hydroponic Gardens,"P6 had a aero hydroponic gardens. First the setup is inaccessible. They wants to read the instruction mannuals and set things up, during which they need to read graphics and charts. Secondly the control is hand-heavy. Currently all companies used different standards so it's hard to use apps to read.",,
P6-17,Interview 2,17:52,Musical instrument keyboard,P6 is a keyboard player. Keyboard has a lot of buttons and icons so it's difficult for them to understand the funciton of each key.,P6 recorded a video of the functions of button.,Use tactile representation of graphs / icons / buttons to inform users.
P7-1,Interview 1,8:41,Read labels,P7 wants to read labels.,P7 used the app Lookout to read. But lightning or angle of camera will affect the OCR.,
P7-2,Interview 1,9:58,Avoid dogs on street,P7 knows there is a dog around them. They want to know where the dog is and keep distance from it.,P7 used the app Lookout to identify the dog and try to localize the dog.,
P7-3,Interview 1,10:59,Outdoor navigation,P7 wants to describe where them are to other people or tell people how to go to a certain places.,P7 used Lookout to read the label on shops. P7 would call friends and tell them about the direction.,"The phone can tell in which direction / distance the object is in the picture, like giving out clock wise directions."
P7-4,Interview 1,17:31,Read photos on social media,"When P7 receives picture on Facebook or WhatsApp, Facebook only says there are two people in the picture, but doesn't estimate their ages.","They share that photo to Sullivan, and it will tell them the estimated age. ",
P7-5,Interview 1,19:05,Access app,Many applications are inaccessible because the text of the buttons does not properly get transmitted to the screen reader. ,P7 took a screenshot of the app and send it to Sullivan.,
P7-6,Interview 1,21:34,Navigation,"Google Maps doesn't tell you where to go in relation to your position. For example it only tells users to go east. Secondly, if users do a mistake, like turning on a wrong road, instead of telling them to go back to the point where they started going wrong, GM reroutes users to something else. ","P7 used WeWALK. It tells them clockwise directions using the phone compass. When they do a mistake, it doesn't reroute them. It tells them to go back and redirecting them to the right route. Using phone compass is ok but using smart cane might be more accurate.",Smart glasses based app is preferred because it's hard to use one hand to hold the phone when they're out.
P7-7,Interview 1,24:27,Explore new city,P7 was in a new city. They wanted to figure out the layout of the city to build an approximate mental map of the city.,P7 used web version of Google Maps. They entered two points and saw the distance between the points. They also used that to estimate price of taxi before ride sharing was around/,The GPS can’t measure places within a certain distance accurately. They also can't customize one's own routes. Sometimes GPS might not plan the easiest way (e.g. less crossing) for BVI people.
P7-8,Interview 1,33:12,Use BIOS,"P7 wanted to read things with tables and columns, edit settings in a BIOS, figure out where something is generally, and control appliances.",P7 make a call with their friends to get help.,
P7-9,Interview 1,38:56,Read images,P7 wants to understand an image. Current assistive apps translate the images into natural,,"For example, the app shouldn't describe a table as a table. It should say a long rectangular things, breaking things into geometric parts. This let users explore the images by shapes. 
In using simple building blocks to describe things, users can interpret themselves and the app can avoid making major mistakes.
P7 also wants to get details about an object. For example, for a car, what kind of car? Is it big? What kind of wheels does it have? They hope they can explore and actually find out the details."
P7-10,Interview 1,52:41,Use websites or computer interfaces,P7 wants some adds-on on screen readers.,,"P7 wants a HRTF, head related transfer functions, which can actually create a free audio virtual environment. Users can the voice from up, down, forward and backwards. If there’s a close button on top right, users can hear information about that x button from upper right corner. So that users can understand the layout of an app first, and second, they can also give directions to others."
P7-11,Interview 2,12:13,Find seats on a bus,P7 wants an app to detect an empty seat on a bus.,,"1. Could be hardware on a bus
2. Could be on a phone and use phone camera. An app could read out seats row by row as user is walking down the corridor"
P7-12,Interview 2,16:38,Navigate around obstacles,"P7 wants 3d, or spatial audio with bone conduction headphones to sonify obstacles while navigating. Because bone conduction headphones are great for outdoor wear",,"1. The technology can use 3d audio to guide users.
2. The technology can use the voice to tell you what object it is in front of you and how big the object is. Maybe the beep sound could grow louder when you approach an object."
P7-13,Interview 2,23:26,color detection,"P7 used an app called The Voice app. It can detect color and tell you by making some noises. But users need a white sheet of paper so the app can understand how light looks like in that environment. P7 wonders if a better method could be found, because they may not have white paper.",,
P8-1,Interview 1,10:55,read subtitles,P8 have friends who watch Japanese anime. They want to know the subtitles.,They used Seeing AI to read the subtitles.,
P8-2,Interview 1,8:56,Read text,P8 want to read text that has Arabic.,"They use Envision AI instead of Seeing AI, because the former can support Arabic better.",
P8-3,Interview 1,12:13,Identify medical labels,P8 was living alone and need to identify some of the medication. They want to check labels or manuals.,They used Seeing AI text recognition to read.,
P8-4,Interview 1,"18:06, 20:41",Use touchscreen ,"P8 wanted to read the keyboard screen of a musical keyboard. They don't know where to click on that keyboard as information was not written on the screen.

Similar touch screen issue happend with microwave.",,P8 want to have technologies that can help them use touchscreens. The technology can use finger tracking and have high accuracy. The system would only read out the text pointed by their fingers.
P8-5,Interview 1,"26:55, 28:49",Find things,"When P8 is outside and needs to locate something, like entrance and exit.","P8 used Be My Eyes, but they keep the call as short as possible because the agent is voluntary. Sometimes the internet connection is bad, and BME couldn't help.",
P8-6,Interview 1,30:16,read text,P8 needs to know what's written on a piece of text but they don't know whether it's in English or Other languages.,"P8 used Seeing AI to first scan it. SA can't support other languages so it will probably read out random things. If that happens, P8 would switch to Envision AI.",
P8-6,Interview 1,38:46,Listen / make schedule,"P8 needs to listen to music or news, or P8 needs to add something onto their schedule.",P8 used voice assistants like Siri or Alexa.,"Android and iPhone have different functionalities and it's inconvinent to switch between appes. More integration between phone and voice assistance, and better universal experience, is desired."
P8-7,Interview 1,41:41,Know what's on a digital screen,P8 wants to know the temperature on a air conditioner remote controller.,"P8 used Tap Tap See to take a photo of the controller, and the app would tell them the temperature. Now Sing AI has similar functions but it doesn't have good accuracy.",- Higher accuracy in detection is desired.
P8-8,Interview 1,56:33,Locate an empty chair,P8 wants to enter a classroom and find an empty chair in that room.,,"P8 doesn't want to wave their phone in the crowd. They could use equipment like smart glasses to scan the environment. The glasses scan the room, find an empty chair, and give directions on how to walk to the chair.
The equipment should not be bulky or expensive, and it could be in any shape, even like a watch."
P8-9,Interview 2,2:05,Read a Graph,P8 studied Compuer Science major in college. They needed to read a lot of graphs when studying.,P8 would ask their friends / families for help. They also know that there are some devices that can let people scan a graph and tell people details of that graph.,"Since device is expensive, they hope it will have app version. The app can tell users a general idea of the graph (e.g. a bar chart) at first. By touching each area the app could tell users information with different sound. Color or different levels of shadow could also be represented by different sounds or pitch or whatever it is. Or the app can take a photo of the graph and form a clear text version of description of the graph, so they can use screen reader to read it. In conslusion, they want the app to provide both speech and non-speech audio."
P8-10,Interview 2,12:13,Read posts on social media,Posts might have multiple images and P8 wants to read them.,"As a PC user, P8 sent the tweet link to his phone and opened from there, and scanned the image. But within current app, when users scan the screen, it will scan everything, but users don't need to know the information they can already access with the screen reader. That is a waste of time. And apps probably ignore the image completely.","People can just scan the screen, and the app will say ""detected three images"" and let users explore each image."
P8-11,Interview 2,18:26,Find cursor on screen,"There are screens screen-readers can't work. Like BIOS screen. When screen readers can't work, P8 also want to know where is the cursor and what area is highlited on the screen.
Some screens are only keyboard-accessible. P8 would also want to use them but don't know what effects would each key on keyboard could make.",,"The system would at first read the screen and tell them function keys e.g. F8 to get the boot menu, F2 to exit.
The system can read a menu if a user opens one, and user can freely stop it .
The system read details like the highlight area.
If they press down any buttons causing the screen to change, the system will notify that new information appear on the screen."
P8-12,Interview 2,22:16,Find stains on clothes,P8 wants to know whether the cloths they're wearing has stains on it or whether it is tidy.,,They can stand in front of the mirror and scan the mirror. The system will notify users with stains.
P8-13,Interview 2,27:21,Outdoor navigation,P8 wants more detailed navigation that can combine augemented reality and gps together.,,"Users can hold their phone camera and scan their surroundings. Camera and gps will cooperate to tell users e.g. this building is on left or ""you need to walk x meters forward""."
P8-14,Interview 2,29:22,Study Math,P8 wants to study and maybe interact with math content on a paper.,,
P9-1,Interview 1,7:33,read text,"Read short electronic documents on either phones or computers.
There is no accessible PDF document. OCR works well on laptop, while it works well on JPG (image format only) on phones.","If it's a PDF on their phone, P9 take a screenshot and do OCR. If it's on laptop, they convert images to pdf then do an OCR.","- No need to take screenshots of pdf.
- Can be done on a ppt.
- Number detection.
- Formatting.
- Being able to work with multiple languages."
P9-2,Interview 1,20:52,Learn Surroundings,Check how much light in a room.,"P9 used Seeing AI, which has a function that can beep loudly when there is light in the room and not beep when the room is dark.",
P9-3,Interview 1,21:38,read image from social media,"P9 wants to check screenshots or images on social media or sent by their families and friends. Those pictures might include both text and images, and P9 needs to know both of them.",Use Seeing AI Image Recognition to know pictures. P9 shared each picture of interest to the Seeing AI app and let the app describe the pictures.,"- There should be no need to share the image to Seeing AI to detect. Can directly use stroke or gesture on the image page to detect. Because current share button has some bugs and sometimes the app can't detect accurately.
- The app could notify users when recognizing a person who has been detected before. Enable users to add name for this person.
- The age and gender detection should be accurate and consistent. If a person is said to be 30, they won't be described as 40 next time."
P9-4,Interview 1,24:18,Check clothes,Know the color of clothes.,Seeing AI Color Recognition,
P9-5,Interview 1,31:22,Outdoor Navigation,"When P9 is out and on a vehicle, they want to share their destinations with drivers. They also want to know where they are when they are on the road.",P9 used Google Map to know their current locations and let dirvers know the destinations in advance.,"The app could have better accuracy in short distances. Now the app is not accurate within around 50 meters, and the driver sometimes let P9 off ahead of destinations. P9 has to tell the drivers which building, etc, to look for."
P9-6,Interview 1,35:23,Indoor Navigation,P9 wants to go to museums or shopping in stores. She wants to know the artworks she stopped by and the detail of products on shelves.,,"'- The system should be live. It can detect real-time positions accurately.
- It should forsee and notify users with potential dangers (e.g. pits, pets).
- It should tell the user things (e.g. things on grocery shelf) around, especially at places users stop. The description should be consistent."
P9-7,Interview 1,47:07,Outdoor Navigation,P9 needs to walk straight line when on a road with possibly 3 crossings.,Google Map. GM would keep alerting users if they didn't turn left at one crossing. They know they are walking straight when keep hearing the alert.,
P9-8,Interview 1,54:04,take a picture,P9 wants to take a picture with her phone. They need to position the camera in the correct position.,"Use Be My Eyes / Aira, let agents tell P9 whether P9 has positioned the camera correctly. Aira agents can even take a picture on their end when the camera is correctly positioned. For BME, P9 has to take the picture themselves.",- BME takes longer while they don't have such long time
P9-9,Interview 1,57:27,Kitchen,"P9 needs to find things, look at labels, or read cooking instructions / calories information on food packages in the kitchen. The text is very short and hard to take a photo with.","P9 asked their family members who live with them for help, as this is more efficient than using Seeing AI.",
P9-10,Interview 1,58:34,Workplace - deal with documents,P9's co-worker needs a table but they only have the image format of that table. Or P9 needs to create Excel sheets.,"P9 took a picture with their phone of the image, did an OCR, and copied-pasted the results to Excel. The results are ok but formatting is not correct. When adjusting formatting, P9 usually just did piece by piece or changed the whole sheets (e.g. first change everything to 12 fonts, then change header to 10 fonts).",Have an alert or warning checking that certain content looks different on X line in X page number.
P9-11,Interview 2,1:14,Need of help indicator,"P9 is outdoor and they need a low-tech indicator to indicate whether they need in-person help from passers-by. So that when they don't need help no one will walk up to them. When they need help, they can still find people to help them without the need to make eye contact with others.",,It could be a cover or something on the cane that they could sort of open the flap or shut it off.
P9-12,Interview 2,5:55,Outdoor Navigation,"P9 encountered time-sensitive outdoor events, for example, wanting to know the number of an incoming bus, or crossing the road. P9 preferred in-person help over AIRA or BME because they think it is difficult to show a moving object in camera while holding the cane. There're also noise in the environment, or could be raining and they don't want to take out their phone. There're other issues like audio, internet connection.",,
P9-13,Interview 2,9:28,BVI identifier on apps,"P9 wants to have identifier on apps like grocery app or Uber to let them know they're blind, so that they can provide better verbal guidance.",,
P9-14,Interview 2,12:27,manipulate zoom audio,P9 needs to work simultaneously with colleagues so they needs to have zoom open while working. Screen readers will mess up with human voices from zoom in this process.,,It's good to have features to delay or skip the zoom voice a little bit without missing important messages.
P10-1,Interview 1,11:35,Differentiate currency,P10 needs to sort and differentiate bills (e.g. $20 bill or a $1 bill) if they get cash from somebody.,"P10 used to use Money Reader, an app doesn't function anymore. Now they use Seeing AI. They would scan the bills with SA, know the number. And then sort them into piles, fold them differently and put them in the wallet, so that they know what's what later. Sometimes if SA can't work, they also switch to a talking CCTV or KNFB.","- SA doesn not have good color detection function, P10 hope it will improve.
- Can have backup solution if detection failed."
P10-2,Interview 1,11:35,Sort mails or other short text,P10 needs to read part of a mail to get a sense of what it's about and is it necessary to read on.,"P10 use Seeing AI's short text channel to first scan it. If they find it's necessary to read, they will use document channel to scan the whole mail and read.",
P10-3,Interview 1,"11:35, 31:07",Read labels or instructions on food in kitchen,"P10 needs to read text on products in the kitchen. For example, cooking instruction on food packages, nutrition facts, expiration dates, medication labels. P10 also want to have accessible prescription labeling.","Some products have barcodes. P10 used Seeing AI barcode reader to scan and get information from the system. They also use short text channel and document channel to directly scan and thus read the instructions or other text on food products. They will start with the short text channel to find where they need to read specifically. Sometimes that will solve their problems. Other times, they have to move on to the document channel, which usually does a pretty good job. To read 2 columns of text, they would listen carefully and figure out that there are 2 columns of text. Then they position their cameras carefully to focus on one column at a time.","The system sometimes doesn't have information for certain products. It should be more comprehensive. On packages of food, there are usually two columns of information, nutrition and instructions, and Seeing AI can't differentiate the columns accurately. They'll try to read the whole thing across. SA could improve to be able to isolate that column, versus trying to read left to right across the whole thing.  Some bottles are round, or very small. Short text detection can't work well. The system should work with odd-shape object."
P10-4,Interview 1,11:35,Use appliance,"P10 has a printer copier to scan things. Printers have digital screens but can't speak. Sometimes they can't know whether it's functioning properly, or got paper stuck, etc. That information only shows on screen.",Ask a friend or use Be My Eyes.,Have an accessible (talking) printer. Or other ways to access the digital screen.
P10-5,Interview 1,11:35,Use TV,"P10 wants to read the screen of other digital devices, like TV.","P10 used Seeing AI to scan, and SA told them the text. But the highlighted area and grayed out area, or areas with multiple lines, can't be told.","When read digital screens, they want to also know the formatting and highlighted info."
P10-6,Interview 1,21:25,Read short text,"P10 is a huge gardener and want to identify seed packets which all feel the same. P10 also wanted to differentiate 2 kinds of their bags of chicken coop, which each has one word on the bag .","P10 use iPhone camera's OCR function to solve this. They scan the packets to know the text on labels. But sometimes there are glossiniess on labels so SA can't detect. 
For the chicken coop bag scenario, P10 scan the whole bag to find where the text could be, then they flatten tthat area and scan again. But the bag is floppy and hard to turn over, so it's hard for them to find the exact word.","Technologies should be able to detect text when text is under non-standar conditions, like glossy or on non-flat surface."
P10-7,Interview 1,35:23:00,Emergency,"P10 was baking something in the oven. When they opened it, they dropped one of the hot pads and they could not find it on the floor. They were really panicked and worried it was dropped into the oven and would catch on fire. They failed to find the pads by themselves because they didn't feel it on the ground and the oven was too hot.","P10 used Be My Eyes to let the agent find the pad. P10 scanned the oven and floor, and the agent found the pad was in a hidden position on the floor.",
P10-8,Interview 1,39:36:00,Use appliance,P10 found their TV couldn't work and needed to find out why.,"P10 used Seeing AI to find the screen saying ""no signal"". Then they used Be My Eyes to find out their cat mess up with the TV's fire stick.",
P10-9,Interview 1,44:56:00,Outdoor Navigation,P10 wanted to navigate their neighborhood a lot.,"P10 use SoundScape and set beacons on, e.g. archway in front of their yard. When they get to that spot, it would let them know by the sound. Google Map also has a pedestrian option for directions.","- Hands-free equipment, such as glasses or necklace."
P10-10,Interview 1,45:56:00,Indoor Navigation,"P10 worked with a local winery, and they need to know where the bathroom was. But they don't want to ask people every time.",,P10 hope Google Map can add more good indoor navigation features.
P10-11,Interview 1,48:03:00,Edit text,"P10 tried write an article based on an interview, so they listened the recording while typing. P10 has to simultaneously hear the keyboard speaking what they typed and the phone's recording. They haven't find the perfect word processing app. Current ones they used were laggy with updating word changes in the document. So they find it hard to edit word.",,
P10-12,Interview 1,58:41:00,Use appliance,"P10 have some instruction manuals or apps that go with products, but they are not accessible. 
P10 has a hydroponic system in their kitchen which can be linked to Wi Fi. There is an app that can help them use that system. The hydroponic system is all digital so P10 hoped to let the system link to Wi Fi and use the app to monitor that system.
P10 got difficulty getting the system connected to Wi Fi.",P10 asked help from people to set the system up.,p10 hoped there could be talking system paired with accessible apps.
P10-13,Interview 1,1:03:08,View aesthetic work,"P10 wants to feel artworks, which is very subjective. They want to know exactly what's there, let technologies tell them more details of the scenes, so that they can make their own interpretation of that art piece.",,
P10-14,Interview 2,2:02,Digital keyboard,"P9 has a piano keyboard. 
1. It's hard to know the current condition of the keyboard. The digital screen of keyboard is a dial that there's not a beginning or end click. P9 can't know if they're at the beginning of a list or the end of a list. 
2. It's hard to know different functions on the keyboard. Each button has different functions. If they push a button, once it's one sound, if pushed twice, it's another sound. Each one of those buttons has three different buttons within the button. It's hard to learn how to use the keyboard.",Play with the keyboard many times and try to remember with trials and Notes on their phone.,"The keyboard can speaks different sounds when different buttons are clicked. And tells the users by clicking different times, what different functions the button could have. And it would be great to enable tracing back their steps.
Seeing AI can read some text on the screen but it can't tell you which text is on which part of the screen. If Seeing AI could add a channel that recognize highlighted text, that could be a solution.
Or have some people to teach them how to use the instrument. But this could take hours."
P10-15,Interview 2,18:57,Find lost objects,"P10 needs help to locate their chickens. They need to find if chickens have escaped from their coop, or have layed an egg in an unusual spot.","P9 had a Facetime call with their friends. Video calls for them are very helpful in finding things they can’t find on their own.
P9 chose friends instead of BME because it's a simple and quick task. If they encountered specialized problems like computer issues they will use BME. 
Seeing AI's object recognition function is not very accurate, and it can't give directions or distance on how to get to the item P9 needs to find.","Seeing AI could 1. Let user input an object; 2. Use object recognition to find the object. If found, beep (like the light detection channel); 3. Give out directions on how to reach the object (if closer to the object, beep sound decreases, otherwise increases)."
P10-16,Interview 2,28:52,read credit card number,"There's no app or CCTV or phone camera can accurately or consistently read the numbers on the credit cards.
Once P9 updated their card but forgot to update the 3-digit code in their note, and they can't use the card.","P9 memorized all the numbers for every card, and wrote them in notes app just in case they forget them.",
P10-17,Interview 2,30:40,POS system,P9 wants to have their own retail service but there is no accessible POS system.,,
P11-1,Interview 1,6:31,Navigation: Find a location,P11 was in a hotel. They pressed the 4 on elevator. The elevator wasn't accessible (couldn't talk) and when the door opened they stepped out the elevator. Sfter that they couldn't find their room. They did not know where the room numer was.,"P11 first used Seeing AI, but failed to find the number. Then they switched to Be My Eyes to ask the volunteers to search for the numbers and read to P11 the numbers on the door. It turned out that firstly the number is high and they didn't position the camera to that height, so SA didn't work. BME provide them with human guidance and found the number. Then they were told that they were on floor 2 instead of 4, probably becase others on floor 2 pressed the button, and the elevator opened on floor 2. P11 incorrectly thought it was floor 4 and went out. BME volunteer told them it's the wrong floor.","The system can tell users what floor they're on. Even the user don't know where target text is, the system can provide helpful guidance."
P11-2,Interview 1,8:11,Find a thing,P11 couldn't find the television in a hotel room.,P11 used Be My Eyes to describe the room and to find out where the television was. They also used Skype to ask help from people they know before BME was available.,
P11-3,Interview 1,13:12,Differentiate things,P11 was in a hotels that provided a sample shower gel and a whole bottle of shower gel. The buttons for the two are the same. P11 wanted to know which was the shower gel and which was the sample.,"P11 used BME. They tried to use other technologies like Seeing AI, but sometimes it's not accurate. So the human high eye is better than the artificial intelligence.",
P11-4,Interview 1,15:52,Use website,P11 wanted to use a website but it was not accessible. P11 can't use BME because they can't keep stay in the app while going to the website and show the website to volunteers.,P11 asked help from families and friends.,It should be possible to share the screen of phone or computers while using the app.
P11-5,Interview 1,27:39:00,Read Text,"Sometimes product labels are written in multiple languages. When p11 wanted to recognize the text on the fly using Seeing AI short text channel, they have to select languages. If they select Italian, but some part is English, the app doesn't recognize. 
It's also challening to scan the label from every angle of the packages for P11. Sometimes detection failed if label is round.",,
P11-6,Interview 1,36:29,Travel,"P11 wanted to go out independently. They also wanted to know the traffic on road before they go out. When they receive navigating instructions on phone they want a route that is safe for blind people, for example maybe a route takes a longer time but with less crossings.","P11 used Google Map and Apple Maps, whichever was more helpful. They would use Be My Eyes as a backup.","P11 wants to schedule volunteer service on BME so that when they go out, they can let the volunteer stay with them and provide help. If a volunteer helped them, they can add the volunteer to a whitelist and maybe next time they can still ask help from that person. Google Maps could provide accessible maps that BVI people could explore different routes without visuals."
P11-7,Interview 1,1:13:19,Use inaccessible software,"P11 is a translator. There is a computer aided translation software, but this is not accessible for blind users. P11 can't ue the software as other translators.",P11 asked other sighted people for help or just not use the software.,"P11 wanted some general solutions to make inaccessible software accessible, without the burden to rewriting the software from scratch."
P11-8,Interview 2,01:58,covid test,"BVI people can't individually take a COVID test. First, they can't read the instruction manual. Second, they can't see the result. Similar problems exist in pregnancy tests.","They can use Be My Eyes, but it's health data and too sensitive to share over internet. Therefore P11 asked a friend or family member for help.",The test kit could beep differently to show different results. There could also be QR code on the package to let BVI people learn how to use the kit.
P12-1,Interview 1,9:44,Fetch a package,P12 had a lot of Amazon packages. They live in a 10 story building and there are usually multile piles of packages. P12 would receive a notification on their phone and go to fetch the package.,"If there are only around 3 packages, P12 would use Seeing AI short text channel to scan the packages. If they hear their name, they can get the package. If there are over 10 packages, they use Aira instead to find their package, because SA wouldn't be efficient in this amount.",
P12-2,Interview 1,16:24,Use inaccessible website,"P12 and their friend wanted to go to a restaurant, so they wanted to look at the menu on the restaurant's website in advance. But their menu wasn't accessible.","P12 took a screenshot of the inaccessible menu, then open Seeing AI and let Seeing AI scan the inaccessible screenshot. But it took longer time. The result would come out halfway decent. It couldn't read out visual clusters on the website but could give them the gist of what's there. If they have no time to do this they would call Aira.","There could be a template for people to put information in, so that assistive technology can just follow the template and read things out, like a McDonald's kiosk."
P12-3,Interview 1,21:07,Position camera,P12 found that to use accessible apps often it requires a steady hand to hold the camera. But it is difficult.,"P12 heard that some people have made like a stand that people can sit their phone on, and then put something underneath it. So it steadies the phone.",
P12-4,Interview 1,25:18,Fill out form / document,P12 wanted to fill out a form online or prepare a document for their colleagues.,"P12 used AIRA’s TeamViewer so that if they’re filling out an application form that's not accessible with JAWS (screen reader), AIRA agents can help with the application. P12 also used AIRA to look over documents e.g. before sending it out to their colleagues. P12 also used AIRA for formatting or spelling / grammar checks. If P12 is filling out a form on an inaccessible website they also get help from AIRA.
P12 generally use AIRA for editting. 
P12 usually keeps the process under 30 min frame. They said calling AIRA has helped them build confidence in their own writing and editting skills.","Sometimes AIRA can't assign users an agent immediately, and people find they pass the deadline to submit somethings. It would be good to know how AIRA prioritize users."
P12-5,Interview 1,27:24,stores on street,P12 was walking on the street and there's a row of shops. They want to figure out one shop from the other without going into each one and ask.,"P12 used AIRA and let them see the sign / text on those buildings, so they can know what those stores are and find their wanted ones. This is very efficient for P12.","BlindSquare could add public transportation information, like bus routes. Or users can call a Uber within the app."
P12-6,Interview 1,40:01,Outdoor navigation,"When P12 is traveling, they wanted to walk around to explore.","BlindSquare give them a sense of where they are going. They can know what street is coming up next. BlindSquare can give them directions to their destination within 100 feet. But distance under that will require their own navigation skills, and it's important for them to know the limit of navigation apps and build their own navigation skills.",
P12-7,Interview 1,43:05,Take Uber,P12's friend took a Uber and they wanted to their the driver which road / highway to go. They also wanted to know what is by the road.,P12's friend used BlindSquare to tell them their current position and the roads ahead of them. So that they could tell the drivers directions.,"BlindSquare could add public transportation information, like bus routes. Or users can call a Uber within the app."
P12-8,Interview 1,46:53,BlindSquare failure,"Sometimes BlindSqaure would fail. When P12 entered a building, signal would become weak. Or sometimes signal becomes weak because of the weather. Then BlindSqaure can't be used but P12 still needs to navigate their way. 
Sometimes BlindSquare has inaccurate gps data.",They would use the Compass app plus voiceover on their phone or use Google Maps.,"BlindSqaure could be updated more frequently or let users know whether it would be updated, what information it gives would be incorrect."
P12-9,Interview 1,51:57,Navigate on campus,P12 wants to walk on campus. Campus has a lot of wierd pathways and don't have regular sidewalks or crossroads -- things P12 relies a lot when they used BlindSqaure to walk in other places.,"P12 used compass app plus voice over. They use it to make sure they are going in the right direction. if they're on a pathway and run into a roadblock, they would try different directions to deviate back. Here their own navigation skills are important.",
P12-10,Interview 1,57:23,Indoor navigation,"If P12 goes to conferences and they’re trying to navigate or find a specific room, general navigation apps can’t work. P12 used AIRA but it’s difficult to listen to someone's instructions and communicate via their phone, while trying to walk or manage other things around them. It’s overload for them. P12 once was at an airport and tried to do AIRA, the environment is very loud and distracting.",,"It would be good to combine BlindSquare and AIRA together to use announcements/ notifications to help BVI people navigate. For example, the system could only tell users “the elevator is on the right” and users can enter the elevator. Users don't have to keep the conversation going.
Or, if there could be something installed inside a building that could could cooperate with BlindSquare, they could navigate independently.
Important information could include floor plan, hallways, rooms, etc."
P12-11,Interview 2,1:04,Workout class,"P12 went to a community center and took workout classes, like a yoga class or a cardio class. They noticed the class is very visual and requires mimicking.",,"There could be connections between smartwatches, headphones, or other wearables with bluetooth, that can detect people's gestures and tell them whether they're doing the right gesture. The system can give audio cues to users."
P12-12,Interview 2,2:02,View artworks,P12 wanted to go to an art gallery.,"Some places provide audio description of artworks, but it's more of a local thing.","They can use gps on wearables to tract the person's location. If a person arrive at a point, the system can provide an audio description of the artwork. 
Or they can provide QR code besides each artwork. People can scan the code, and get information about information like name, background, author, medium, etc."
P12-13,Interview 2,7:05,outdoor running,P12 was having outdoor running. There were some people on lane one so they need to avoid running into those people.,,"Have cues from smartwatches they wear. Cues could be about people around them, blocks on road, etc."
P12-14,Interview 2,19:34,cooking,P12 wanted to cook and read text on food packages. they want to find nutritional facts and ingredients.,"They used Seeing AI and scan the whole package. But SA only read out baking instructions. They re-scaned but SA kept reading out baking instructions. Sometimes SA gives out wrong information, like saying 3500 degress instead of 350.",Have some AT to read out a specific piece of text.